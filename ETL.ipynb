{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modulos de python\n",
    "import ast\n",
    "\n",
    "# modulos de terceros\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importacion solo de las librerias a utilizar durante el ETL de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>15602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
       "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
       "      <td>31357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>11862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45471</th>\n",
       "      <td>[{'cast_id': 0, 'character': '', 'credit_id': ...</td>\n",
       "      <td>[{'credit_id': '5894a97d925141426c00818c', 'de...</td>\n",
       "      <td>439050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45472</th>\n",
       "      <td>[{'cast_id': 1002, 'character': 'Sister Angela...</td>\n",
       "      <td>[{'credit_id': '52fe4af1c3a36847f81e9b15', 'de...</td>\n",
       "      <td>111109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45473</th>\n",
       "      <td>[{'cast_id': 6, 'character': 'Emily Shaw', 'cr...</td>\n",
       "      <td>[{'credit_id': '52fe4776c3a368484e0c8387', 'de...</td>\n",
       "      <td>67758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45474</th>\n",
       "      <td>[{'cast_id': 2, 'character': '', 'credit_id': ...</td>\n",
       "      <td>[{'credit_id': '533bccebc3a36844cf0011a7', 'de...</td>\n",
       "      <td>227506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45475</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'credit_id': '593e676c92514105b702e68e', 'de...</td>\n",
       "      <td>461257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    cast  \\\n",
       "0      [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1      [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "2      [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
       "3      [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
       "4      [{'cast_id': 1, 'character': 'George Banks', '...   \n",
       "...                                                  ...   \n",
       "45471  [{'cast_id': 0, 'character': '', 'credit_id': ...   \n",
       "45472  [{'cast_id': 1002, 'character': 'Sister Angela...   \n",
       "45473  [{'cast_id': 6, 'character': 'Emily Shaw', 'cr...   \n",
       "45474  [{'cast_id': 2, 'character': '', 'credit_id': ...   \n",
       "45475                                                 []   \n",
       "\n",
       "                                                    crew      id  \n",
       "0      [{'credit_id': '52fe4284c3a36847f8024f49', 'de...     862  \n",
       "1      [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...    8844  \n",
       "2      [{'credit_id': '52fe466a9251416c75077a89', 'de...   15602  \n",
       "3      [{'credit_id': '52fe44779251416c91011acb', 'de...   31357  \n",
       "4      [{'credit_id': '52fe44959251416c75039ed7', 'de...   11862  \n",
       "...                                                  ...     ...  \n",
       "45471  [{'credit_id': '5894a97d925141426c00818c', 'de...  439050  \n",
       "45472  [{'credit_id': '52fe4af1c3a36847f81e9b15', 'de...  111109  \n",
       "45473  [{'credit_id': '52fe4776c3a368484e0c8387', 'de...   67758  \n",
       "45474  [{'credit_id': '533bccebc3a36844cf0011a7', 'de...  227506  \n",
       "45475  [{'credit_id': '593e676c92514105b702e68e', 'de...  461257  \n",
       "\n",
       "[45476 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cargar datos de los creditos\n",
    "path = './data/credits.csv'\n",
    "data_cd = pd.read_csv(path)\n",
    "data_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cd['cast'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> carga de los datos de 'credits' y se evalua su informacion para poder proceder con las transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar los datos de todas las columnas.\n",
    "data_cd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos de 'movies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos de las Peliculas.\n",
    "path = './data/movies_dataset.csv'\n",
    "data_movies = pd.read_csv(path, low_memory=False)\n",
    "data_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Una vez cargado los datos se realiza una evaluacion e interpretacion para proceder con la limpueza y estructuracion del conjunto de datos (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar columna 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar los datos de tipo int a str\n",
    "data_cd['id'] = data_cd['id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se tomo la decision de hacer un merge de ambos data sets con el fin de facilitar navegacion relacional de los datos entre las columnas, para ello era requerida la transformacion de la columna 'id' en los datos de 'credits' para poder manejar el mismo tipo de datos en ambas columnas y pueda hacerse un merge de ambos dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinar Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinar datasets\n",
    "data = pd.merge(data_movies, data_cd, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar data combinada\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer datos de los jsons anidados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para extraer los datos anidados en listas.\n",
    "def extract_list_str(list_str):\n",
    "    '''la funcion realiza un casteo de str dependiendo\n",
    "    de la sintaxis al tipo de estructura que se reconozca \n",
    "    para manipularse y retornar datos de la pelicula como str\n",
    "      '''\n",
    "    # Manejo de errores.\n",
    "    try:\n",
    "        # condicion para verificar que la el contexto del str no sea para una lista vacia.\n",
    "        if list_str != '[]':\n",
    "\n",
    "            # Usar el modulo ast para castear la el tipo a la estructura deseada.\n",
    "            list_ = ast.literal_eval(list_str)\n",
    "            # unir valores de la lista de js mediante lista comprimida y join.\n",
    "            return ', '.join([dic['name'] for dic in list_])\n",
    "        else:\n",
    "            # Retornar NoData si es una lista vacia.\n",
    "            return 'NoData'\n",
    "    except:\n",
    "        # Retornar NoData si es un valor nulo o existe otro tipo de error.\n",
    "        return 'NoData'\n",
    "\n",
    "\n",
    "# Definir una función para extraer los datos anidados de .\n",
    "def extract_json_str(collection):\n",
    "    '''la funcion realiza un casteo de str dependiendo\n",
    "    de la sintaxis al tipo de estructura que se reconozca \n",
    "    para manipularse y retornar la coleccion de la pelicula como str\n",
    "      '''\n",
    "    # Manejo de errores.\n",
    "    try:\n",
    "        # Usar el modulo ast para castear la el tipo a la estructura deseada.\n",
    "        collection_dict = ast.literal_eval(collection)\n",
    "        # Devolver el valor extraido del diccionario.\n",
    "        return collection_dict['name']\n",
    "    except:\n",
    "        # Retornar NoData si es un valor nulo o existe otro tipo de error.\n",
    "        return 'NoData'\n",
    "\n",
    "# Definir una función para extraer los datos anidados de genres.\n",
    "def extract_director(director):\n",
    "    '''la funcion realiza un casteo de str dependiendo\n",
    "    de la sintaxis al tipo de estructura que se reconozca \n",
    "    para manipularse y retornar datos de la pelicula como str\n",
    "      '''\n",
    "    # Manejo de errores.\n",
    "    try:\n",
    "        # condicion para verificar que la el contexto del str no sea para una lista vacia.\n",
    "        if director != '[]':\n",
    "            # Usar el modulo ast para castear la el tipo a la estructura deseada.\n",
    "            list_ = ast.literal_eval(director)\n",
    "            # For para iterar la lista y encontrar el director entre el crew.\n",
    "            for i in list_:\n",
    "                if i['job'] == 'Director':\n",
    "                    return i['name']\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            # Retornar NoData si es una lista vacia.\n",
    "            return 'NoData'\n",
    "    except:\n",
    "        # Retornar NoData si es un valor nulo o existe otro tipo de error.\n",
    "        return 'NoData'\n",
    "\n",
    "# Aplicar las funciones de extracción a las columnas correspondientes\n",
    "data['genres_clean'] = data['genres'].apply(extract_list_str)\n",
    "data['collection_clean'] = data['belongs_to_collection'].apply(extract_json_str)\n",
    "data['production_companies_clean'] = data['production_companies'].apply(extract_list_str)\n",
    "data['production_countries_clean'] = data['production_countries'].apply(extract_list_str)\n",
    "data['spoken_languages_clean'] = data['spoken_languages'].apply(extract_list_str)\n",
    "data['cast_clean'] = data['cast'].apply(extract_list_str)\n",
    "data['crew_clean'] = data['crew'].apply(extract_director)\n",
    "# Mostrar las primeras filas del dataframe con las nuevas columnas\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "de errores mediante try an except\n",
    "        en donde si no hay errores el bloque se realizara una validacion mediante un if\n",
    "        que validara que no tenga el str un formato de lista vacia, no ser asi\n",
    "        mediante el modulo ast que analiza la sintaxis\n",
    "        de un string se hace un casteo automatico segun el texto, \n",
    "        para luego poder demanera mas sencilla manipular el dato como una lista\n",
    "        iterandolo mediante una lista por compresion y a su vez el metodo join va agregando\n",
    "        cada elemento como un string separados por una coma y un espacio (', ') que al final sera\n",
    "          retornado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_colums = ['video','poster_path', 'homepage','imdb_id','adult','poster_path',\n",
    "               'tagline','original_language', 'belongs_to_collection','genres',\n",
    "               'production_companies','production_countries','spoken_languages',\n",
    "                'cast', 'crew'\n",
    "            ]\n",
    "data = data.drop(columns=drop_colums)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llenar valores nulos de 'revenue' y 'budget'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revenue'] = data['revenue'].fillna(0)\n",
    "data['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['revenue'][data['revenue'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['budget'] = data['budget'].astype('float64')\n",
    "type(data['budget'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminar valores nulos de 'release_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.dropna(subset=['release_date'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['release_date'][45461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizar fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.release_date = pd.to_datetime(data['release_date'], format='%Y-%m-%d', errors='coerce')\n",
    "data.loc[:, 'release_date'] = pd.to_datetime(data['release_date'], format='%Y-%m-%d', errors='coerce')\n",
    "data['release_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear columna 'release_year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'release_year'] = data['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['release_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear columna 'retorno_de_inversion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.loc[:, 'retorno_de_inversion'] = data.apply(lambda row: row['revenue']/row['budget'] if row['budget'] !=0 else 0, axis=1)\n",
    "data.loc[:, 'retorno_de_inversion'] = data.apply(lambda row: row['revenue'] / row['budget'] if row['budget'] != 0 else 0, axis=1)\n",
    "data['retorno_de_inversion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
